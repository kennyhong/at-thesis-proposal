@article{Okamoto2015,
abstract = {This article presents general principles and recent advancements in the clinical application of augmented reality-based navigation surgery (AR based NS) for abdominal procedures and includes a description of our clinical trial and subsequent outcomes. Moreover, current problems and future aspects are discussed. The development of AR-based NS in the abdomen is delayed compared with another field because of the problem of intraoperative organ deformations or the existence of established modalities. Although there are a few reports on the clinical use of AR-based NS for digestive surgery, sophisticated technologies in urology have often been reported. However, the rapid widespread use of video- or robot assisted surgeries requires this technology. We have worked to develop a system of AR-based NS for hepatobiliary and pancreatic surgery. Then we developed a short rigid scope that enables surgeons to obtain 3D view. We recently focused on pancreatic surgery, because intraoperative organ shifting is minimal. The position of each organ in overlaid image almost corresponded with that of the actual organ with about 5 mm of mean registration errors. Intraoperative information generated from this system provided us with useful navigation. However, AR-based NS has several problems to overcome such as organ deformity, evaluation of utility, portability or cost.},
author = {Okamoto, Tomoyoshi and Onda, Shinji and Yanaga, Katsuhiko and Suzuki, Naoki and Hattori, Asaki},
doi = {10.1007/s00595-014-0946-9},
file = {:C$\backslash$:/Users/KennyHong/Downloads/s00595-014-0946-9.pdf:pdf},
isbn = {1365-182X},
issn = {14362813},
journal = {Surgery Today},
keywords = {Abdominal field,Augmented reality,Navigation surgery,Video see through system},
number = {4},
pages = {397--406},
pmid = {24898629},
title = {{Clinical application of navigation surgery using augmented reality in the abdominal field}},
volume = {45},
year = {2015}
}
@article{Chen2015,
abstract = {The surgical navigation system has experienced tremendous development over the past decades for minimizing the risks and improving the precision of the surgery. Nowadays, Augmented Reality (AR)-based surgical navigation is a promising technology for clinical applications. In the AR system, virtual and actual reality are mixed, offering real-time, high-quality visualization of an extensive variety of information to the users (Moussa et al., 2012) [1]. For example, virtual anatomical structures such as soft tissues, blood vessels and nerves can be integrated with the real-world scenario in real time. In this study, an AR-based surgical navigation system (AR-SNS) is developed using an optical see-through HMD (head-mounted display), aiming at improving the safety and reliability of the surgery. With the use of this system, including the calibration of instruments, registration, and the calibration of HMD, the 3D virtual critical anatomical structures in the head-mounted display are aligned with the actual structures of patient in real-world scenario during the intra-operative motion tracking process. The accuracy verification experiment demonstrated that the mean distance and angular errors were respectively 0.809. ±. 0.05. mm and 1.038°. ±. 0.05°, which was sufficient to meet the clinical requirements.},
author = {Chen, Xiaojun and Xu, Lu and Wang, Yiping and Wang, Huixiang and Wang, Fang and Zeng, Xiangsen and Wang, Qiugen and Egger, Jan},
doi = {10.1016/j.jbi.2015.04.003},
file = {:C$\backslash$:/Users/KennyHong/Downloads/1-s2.0-S1532046415000702-main.pdf:pdf},
isbn = {9781607507055},
issn = {15320464},
journal = {Journal of Biomedical Informatics},
keywords = {Augmented reality,Intra-operative motion tracking,Optical see-through HMD,Surgical navigation},
pages = {124--131},
pmid = {25882923},
title = {{Development of a surgical navigation system based on augmented reality using an optical see-through head-mounted display}},
volume = {55},
year = {2015}
}
@article{Bhorkar2017,
abstract = {Navigation has been a popular area of research in both academia and industry. Combined with maps, and different localization technologies, navigation systems have become robust and more usable. By combining navigation with augmented reality, it can be improved further to become realistic and user friendly. This paper surveys existing researches carried out in this area, describes existing techniques for building augmented reality navigation systems, and the problems faced.},
archivePrefix = {arXiv},
arxivId = {1708.05006},
author = {Bhorkar, Gaurav},
doi = {10.1561/1100000049},
eprint = {1708.05006},
file = {:C$\backslash$:/Users/KennyHong/Downloads/1708.05006.pdf:pdf},
isbn = {1551-3955},
issn = {1551-3955},
keywords = {augmented reality,navigation systems},
pmid = {9708264137},
title = {{A Survey of Augmented Reality Navigation}},
url = {http://arxiv.org/abs/1708.05006},
year = {2017}
}
@article{Ens2014,
abstract = {As wearable computing goes mainstream, we must improve the state of interface design to keep users productive with natural-feeling interactions. We present the Personal Cockpit, a solution for mobile multitasking on head-worn displays. We appropriate empty space around the user to situate virtual windows for use with direct input. Through a design-space exploration, we run a series of user studies to fine-tune our layout of the Personal Cockpit. In our final evaluation, we compare our design against two baseline interfaces for switching between everyday mobile applications. This comparison highlights the deficiencies of current view-fixed displays, as the Personal Cockpit provides a 40{\%} improvement in application switching time. We demonstrate of several useful implementations and a discussion of important problems for future implementation of our design on current and near-future wearable devices.},
author = {Ens, Barrett M. and Finnegan, Rory and Irani, Pourang P.},
doi = {10.1145/2556288.2557058},
file = {:C$\backslash$:/Users/KennyHong/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Ens, Finnegan, Irani - 2014 - The personal cockpit A Spatial Interface for Effective Task Switching on Head-Worn Displays.pdf:pdf},
isbn = {9781450324731},
journal = {Proceedings of the 32nd annual ACM conference on Human factors in computing systems - CHI '14},
number = {August 2016},
pages = {3171--3180},
title = {{The personal cockpit: A Spatial Interface for Effective Task Switching on Head-Worn Displays}},
url = {http://doi.acm.org/10.1145/2556288.2557058{\%}5Cnhttp://dl.acm.org/ft{\_}gateway.cfm?id=2557058{\&}type=pdf{\%}5Cnhttp://dl.acm.org/citation.cfm?doid=2556288.2557058},
year = {2014}
}
@book{Chan2017,
abstract = {Agile software development is characterized by very intensive commu- nication and collaboration among members of the software development team and external stakeholders. In this context, we look specifically at cardwalls, noting that despite the wide availability of digital cardwalls,most Agile teams still use physical cardwalls to support their collaborative events. This is true even though a physical cardwall hinders efficient distributed software development and causes extra effort to capture story artefacts into digital tools to meet traceability and persistence require- ments.We conducted two empirical studies in industry to understand the use of exist- ing digital Agile cardwalls and to find out the needs for an ideal digital Agile card- wall. The first study was with eight Agile teams of committed digital cardwall users. The study showed the reasons why some teams use projected digital cardwalls and their detailed experiences with them. The study showed that most digital cardwalls seem not be sufficient for the highly interactive and collaborative Agile workstyle. The second study was with eleven Agile companies. The study comprised of the development of aWall, a software prototype of a large interactive high-resolution multi-touch display that supports varied Agile meetings where cardwalls are used. The results of the study emerged with design considerations for digital Agile card- walls from the evaluation of aWall in a user workshop. Both studies, which were},
author = {Chan, Edwin and Anslow, Craig and Seyed, Teddy and Maurer, Frank},
booktitle = {Collaboration Meets Interactive Spaces},
doi = {10.1007/978-3-319-45853-3_15},
file = {:C$\backslash$:/Users/KennyHong/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Chan et al. - 2017 - Envisioning the emergency operations centre of the future.pdf:pdf},
isbn = {9783319458533},
pages = {349--372},
title = {{Envisioning the emergency operations centre of the future}},
year = {2017}
}
@article{Barsom2016,
abstract = {Background: Computer-based applications are increasingly used to support the training of medical professionals. Augmented reality applications (ARAs) render an interactive virtual layer on top of reality. The use of ARAs is of real interest to medical education because they blend digital elements with the physical learning environment. This will result in new educational opportunities. The aim of this systematic review is to investigate to which extent augmented reality applications are currently used to validly support medical professionals training. Methods: PubMed, Embase, INSPEC and PsychInfo were searched using predefined inclusion criteria for relevant articles up to August 2015. All study types were considered eligible. Articles concerning AR applications used to train or educate medical professionals were evaluated. Results: Twenty-seven studies were found relevant, describing a total of seven augmented reality applications. Applications were assigned to three different categories. The first category is directed toward laparoscopic surgical training, the second category toward mixed reality training of neurosurgical procedures and the third category toward training echocardiography. Statistical pooling of data could not be performed due to heterogeneity of study designs. Face-, construct- and concurrent validity was proven for two applications directed at laparoscopic training, face- and construct validity for neurosurgical procedures and face-, content- and construct validity in echocardiography training. In the literature, none of the ARAs completed a full validation process for the purpose of use. Conclusion: Augmented reality applications that support blended learning in medical training have gained public and scientific interest. In order to be of value, applications must be able to transfer information to the user. Although promising, the literature to date is lacking to support such evidence. {\textcopyright} 2016 The Author(s)},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {Barsom, E. Z. and Graafland, M. and Schijven, M. P.},
doi = {10.1007/s00464-016-4800-6},
eprint = {arXiv:1011.1669v3},
file = {:C$\backslash$:/Users/KennyHong/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Barsom, Graafland, Schijven - 2016 - Systematic review on the effectiveness of augmented reality applications in medical training.pdf:pdf},
isbn = {09302794 (ISSN)},
issn = {14322218},
journal = {Surgical Endoscopy and Other Interventional Techniques},
keywords = {Augmented reality,Medical education,Medical specialist training,Surgery,Training},
number = {10},
pages = {4174--4183},
pmid = {26905573},
publisher = {Springer US},
title = {{Systematic review on the effectiveness of augmented reality applications in medical training}},
volume = {30},
year = {2016}
}
@article{Ens2015,
abstract = {We introduce a layout manager that exploits the robust sensing capabilities of next-generation head-worn displays by embedding virtual application windows in the user's surroundings. With the aim of allowing users to find applications quickly, our approach leverages spatial memory of a known body-centric configuration. The layout manager balances multiple constraints to keep layouts consistent across environments while observing geometric and visual features specific to each locale. We compare various constraint weighting schemas and discuss outcomes of this approach applied to models of two test environments.},
author = {Ens, Barrett and Ofek, Eyal and Bruce, Neil and Irani, Pourang},
doi = {10.1145/2788940.2788954},
file = {:C$\backslash$:/Users/KennyHong/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Ens et al. - 2015 - Spatial Constancy of Surface-Embedded Layouts across Multiple Environments.pdf:pdf},
isbn = {9781450337038},
journal = {Proceedings of the 3rd ACM Symposium on Spatial User Interaction - SUI '15},
number = {September},
pages = {65--68},
title = {{Spatial Constancy of Surface-Embedded Layouts across Multiple Environments}},
url = {http://dl.acm.org/citation.cfm?doid=2788940.2788954},
year = {2015}
}
@article{Li2009,
abstract = {Abstract Triggering shortcuts or actions on a mobile device often requires a long sequence of key presses. Because the functions of buttons are highly dependent on the current application's context, users are required to look at the display during interaction , even in ... $\backslash$n},
author = {Li, F and Dearman, D and Truong, K},
doi = {10.1145/1622176.1622200},
file = {:C$\backslash$:/Users/KennyHong/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Li, Dearman, Truong - 2009 - Virtual shelves interactions with orientation aware devices.pdf:pdf},
isbn = {9781605587455},
journal = {Uist 2009},
pages = {125--128},
title = {{Virtual shelves: interactions with orientation aware devices}},
url = {http://dl.acm.org/citation.cfm?id=1622200{\%}5Cnpapers://c80d98e4-9a96-4487-8d06-8e1acc780d86/Paper/p10437},
year = {2009}
}
@article{Ball2008,
abstract = {Large high-resolution displays have been shown to improve user performance over standard displays on many large-scale visualization tasks. But what is the reason for the improvement? The two most cited reasons for the advantage are (1) the wider field of view that exploits peripheral vision to provide context, and (2) the opportunity for physical navigation (e.g. head turning, walking, etc.) to visually access information. Which of these two factors is the key to advantage? Or, do they both work together to produce a combined advantage? This paper reports on an experiment that separates peripheral vision and physical navigation as independent variables. Results indicate that, for most of the tasks tested, increased physical navigation opportunity is more critical to improving performance than increased field of view. Some evidence indicates a valuable combined role.},
author = {Ball, Robert and North, Chris},
file = {:C$\backslash$:/Users/KennyHong/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Ball, North - 2008 - The effects of peripheral vision and physical navigation on large scale visualization.pdf:pdf},
isbn = {978-1-56881-423-0},
issn = {0713-5424},
journal = {GI '08: Proceedings of graphics interface 2008},
pages = {9--16},
title = {{The effects of peripheral vision and physical navigation on large scale visualization}},
url = {http://portal.acm.org/citation.cfm?id=1375714.1375717},
year = {2008}
}
@article{Grudin2001,
abstract = {Software today does not help us partition our digital worlds effectively. We must organize them ourselves. This field study of users of multiple monitors examines how people with a lot of display space arrange information. Second monitors are generally used for secondary activities related to principal tasks, for peripheral awareness of information that is not the main focus, and for easy access to resources. A second monitor improves efficiency in ways that are difficult to measure yet can have substantial subjective benefit. The study concludes with illustrations of shortcomings of today's systems and applications: The way we work could be improved at relatively low cost.},
author = {Grudin, Jonathan},
doi = {10.1145/365024.365312},
file = {:C$\backslash$:/Users/KennyHong/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Grudin - 2001 - Partitioning DigitalWorlds Focal and Peripheral Awareness in Multiple Monitor Use.pdf:pdf},
isbn = {1581133278},
journal = {Chi '01},
keywords = {awareness,displays,multiple monitors},
pages = {458--465},
title = {{Partitioning DigitalWorlds: Focal and Peripheral Awareness in Multiple Monitor Use}},
url = {http://dl.acm.org/citation.cfm?id=365312},
year = {2001}
}
@article{Bell2001,
author = {Bell, B and Feiner{\ldots}, S},
file = {:C$\backslash$:/Users/KennyHong/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Bell, Feiner{\ldots} - 2001 - View management for virtual and augmented reality.pdf:pdf},
journal = {Proceedings of the 14th annual ACM {\ldots}},
pages = {101--110},
title = {{View management for virtual and augmented reality}},
url = {http://portal.acm.org/citation.cfm?id=502363},
volume = {2001},
year = {2001}
}
@article{Billinghurst,
abstract = {2D windows-based interfaces may not be appropriate for wearable computers. We draw on virtual reality techniques to design and evaluate alternative methods for information presentation in a wearable environment. We find that simple body-stabilised displays provide benefits over traditional head-stabilised displays. Users find body-stabilised displays easier to use, more enjoyable and more intuitive, and are able to perform better on a search task. Spatial audio and visual cues further enhance performance.},
author = {Billinghurst, M. and Bowskill, J. and Dyer, N. and Morphett, J.},
doi = {10.1109/VRAIS.1998.658418},
file = {:C$\backslash$:/Users/KennyHong/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Billinghurst et al. - Unknown - An evaluation of wearable information spaces.pdf:pdf},
isbn = {0-8186-8362-7},
issn = {1},
journal = {Proceedings. IEEE 1998 Virtual Reality Annual International Symposium (Cat. No.98CB36180)},
keywords = {4,half in the case,have dramatically,improved user performance,in such applications wearables,of vehicle inspection,reducing task time by},
pages = {20--27},
title = {{An evaluation of wearable information spaces}},
url = {http://ieeexplore.ieee.org/document/658418/}
}
@article{Patterson2006,
abstract = {OBJECTIVE: We provide a review and analysis of much of the published literature on visual perception issues that impact the design and use of head-mounted displays (HMDs). BACKGROUND: Unlike the previous literature on HMDs, this review draws heavily from the basic vision literature in order to help provide insight for future design solutions for HMDs. METHOD: Included in this review are articles and books found cited in other works as well as articles and books obtained from an Internet search. RESULTS: Issues discussed include the effect of brightness and contrast on depth of field, dark focus, dark vergence, and perceptual constancy; the effect of accommodation-vergence synergy on perceptual constancy, eyestrain, and discomfort; the relationship of field of view to the functioning of different visual pathways and the types of visual-motor tasks mediated by them; the relationship of binocular input to visual suppression; and the importance of head movements, head tracking, and display update lag. CONCLUSION: This paper offers a set of recommendations for the design and use of HMDs. APPLICATION: Consideration of the basic vision literature will provide insight for future design solutions for HMDs.},
author = {Patterson, Robert and Winterbottom, Marc D. and Pierce, Byron J.},
doi = {10.1518/001872006778606877},
file = {:C$\backslash$:/Users/KennyHong/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Patterson, Winterbottom, Pierce - 2006 - Perceptual Issues in the Use of Head-Mounted Visual Displays.pdf:pdf},
isbn = {0018-7208},
issn = {0018-7208},
journal = {Human Factors: The Journal of the Human Factors and Ergonomics Society},
number = {3},
pages = {555--573},
pmid = {17063969},
title = {{Perceptual Issues in the Use of Head-Mounted Visual Displays}},
url = {http://journals.sagepub.com/doi/10.1518/001872006778606877},
volume = {48},
year = {2006}
}
@article{Hastings1979,
author = {Hastings, W K},
file = {:C$\backslash$:/Users/KennyHong/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Hastings - 1979 - Monte Carlo Sampling Methods Using Markov Chains and Their Applications.pdf:pdf},
journal = {Biometrika},
number = {1},
pages = {97--109},
title = {{Monte Carlo Sampling Methods Using Markov Chains and Their Applications}},
volume = {57},
year = {1979}
}
@article{Ens2014a,
abstract = {Information spaces are virtual workspaces that help us manage information by mapping it to the physical environment. This widely influential concept has been interpreted in a variety of forms, often in conjunction with mixed reality. We present Ethereal Planes, a design framework that ties together many existing variations of 2D information spaces. Ethereal Planes is aimed at assisting the design of user interfaces for next-generation technologies such as head-worn displays. From an extensive literature review, we encapsulated the common attributes of existing novel designs in seven design dimensions. Mapping the reviewed designs to the framework dimensions reveals a set of common usage patterns. We discuss how the Ethereal Planes framework can be methodically applied to help inspire new designs. We provide a concrete example of the framework's utility during the design of the Personal Cockpit, a window management system for head-worn displays.},
author = {Ens, Barrett and Hincapi{\'{e}}-Ramos, Juan David and Irani, Pourang},
doi = {10.1145/2659766.2659769},
file = {:C$\backslash$:/Users/KennyHong/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Ens, Hincapi{\'{e}}-Ramos, Irani - 2014 - Ethereal Planes A Design Framework for 2D Information Space in 3D Mixed Reality Environments.pdf:pdf},
isbn = {978-1-4503-2820-3},
issn = {9781450328203},
journal = {Proceedings of the 2Nd ACM Symposium on Spatial User Interaction},
pages = {2--12},
title = {{Ethereal Planes: A Design Framework for 2D Information Space in 3D Mixed Reality Environments}},
url = {http://doi.acm.org/10.1145/2659766.2659769},
year = {2014}
}
@article{Cie1999,
author = {Cie, Dennis R Ankrum and Ergonomics, D R Visual and Guidelines, Office and Health, Occupational},
file = {:C$\backslash$:/Users/KennyHong/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Cie et al. - 1999 - Monitor Placement and Lighting Visual Ergonomics in the Office Summary Guidelines for monitor placement and lightin.pdf:pdf},
title = {{Monitor Placement and Lighting Visual Ergonomics in the Office Summary : Guidelines for monitor placement and lighting EYE-TO-SCREEN DISTANCE}},
year = {1999}
}
@article{Nuernberger2016,
abstract = {(a) (b) (c) (d) Figure 1: SnapToReality allows users to easily position, orient, and scale AR virtual content with respect to real world constraints. Our prototype (a) extracts real world planar surfaces and edges as constraints so that users can easily align virtual content to the real world via snapping (b, c). SnapToReality techniques enable the seamless integration of AR content into the real world (d). ABSTRACT Augmented Reality (AR) applications may require the precise alignment of virtual objects to the real world. We propose automatic alignment of virtual objects to physical constraints calculated from the real world in real time (" snapping to reality "). We demonstrate SnapToReality alignment techniques that allow users to position, rotate, and scale virtual content to dynamic, real world scenes. Our proof-of-concept prototype extracts 3D edge and planar surface constraints. We furthermore discuss the unique design challenges of snapping in AR, including the user's limited field of view, noise in constraint extraction, issues with changing the view in AR, visualizing constraints, and more. We also report the results of a user study evaluating SnapToReality, confirming that aligning objects to the real world is significantly faster when assisted by snapping to dynamically extracted constraints. Perhaps more importantly, we also found that snapping in AR enables a fresh and expressive form of AR content creation.},
author = {Nuernberger, Benjamin and Ofek, Eyal and Benko, Hrvoje and Wilson, Andrew D.},
doi = {10.1145/2858036.2858250},
file = {:C$\backslash$:/Users/KennyHong/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Nuernberger et al. - 2016 - SnapToReality Aligning Augmented Reality to the Real World.pdf:pdf},
isbn = {9781450333627},
journal = {Proceedings of the 2016 CHI Conference on Human Factors in Computing Systems - CHI '16},
keywords = {CHI 2016},
pages = {1233--1244},
title = {{SnapToReality: Aligning Augmented Reality to the Real World}},
url = {http://dl.acm.org/citation.cfm?doid=2858036.2858250},
year = {2016}
}
@article{Feiner1993,
abstract = {We describe the design and implementation of a prototype heads-up window system intended for use in a 3D environment. Our system includes a see-through head-mounted display that runs a full X server whose image is overlaid on the user's view of the physical world. The user's head is tracked so that the display indexes into a large X bitmap, effectively placing the user inside a display space that is mapped onto part of a surrounding virtual sphere. By tracking the user's body, and interpreting head motion rela- tive to it, we create a portable information surround that envelopes the user as they move about.},
author = {Feiner, Steven and MacIntyre, Blair and Haupt, Marcus and Solomon, Eliot},
doi = {10.1145/168642.168657},
file = {:C$\backslash$:/Users/KennyHong/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Feiner et al. - 1993 - Windows on the world.pdf:pdf},
isbn = {089791628X},
journal = {Proceedings of the 6th annual ACM symposium on User interface software and technology  - UIST '93},
number = {July},
pages = {145--155},
pmid = {47589},
title = {{Windows on the world}},
url = {http://portal.acm.org/citation.cfm?doid=168642.168657},
year = {1993}
}
@article{Gal2014,
abstract = {Creating a layout for an augmented reality (AR) application which embeds virtual objects in a physical environment is difficult as it must adapt to any physical space. We propose a rule-based framework for generating object layouts for AR applications. Under our framework, the developer of an AR application specifies a set of rules (constraints) which enforce self-consistency (rules regarding the inter-relationships of application components) and scene-consistency (application components are consistent with the physical environment they are placed in). When a user enters a new environment, we create, in real-time, a layout for the application, which is consistent with the defined constraints (as much as possible). We find the optimal configurations for each object by solving a constraint-satisfaction problem. Our stochastic move making algorithm is domain-aware, and allows us to efficiently converge to a solution for most rule-sets. In the paper we demonstrate several augmented reality applications that automatically adapt to different rooms and changing circumstances in each room.},
author = {Gal, Ran and Shapira, Lior and Ofek, Eyal and Kohli, Pushmeet},
doi = {10.1109/ISMAR.2014.6948429},
file = {:C$\backslash$:/Users/KennyHong/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Gal et al. - 2014 - FLARE Fast layout for augmented reality applications.pdf:pdf},
isbn = {9781479961849},
issn = {978-1-4799-6184-9},
journal = {ISMAR 2014 - IEEE International Symposium on Mixed and Augmented Reality - Science and Technology 2014, Proceedings},
keywords = {F.4.1 [Mathematical Logic]: Logic and Constraint P,G.3 [Probability and Statistics],Markov Processes},
number = {August},
pages = {207--212},
title = {{FLARE: Fast layout for augmented reality applications}},
year = {2014}
}
@article{Hoffman2010,
author = {Hoffman, David M and Banks, Martin S},
doi = {10.1167/8.3.33.Vergence},
file = {:C$\backslash$:/Users/KennyHong/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Hoffman, Banks - 2010 - and Cause Visual Fatigue.pdf:pdf},
keywords = {3d display,accommodation,binocular vision,cue combination,depth perception,fatigue,graphics,stereopsis,vergence,visual,volumetric display},
number = {3},
pages = {1--48},
title = {{and Cause Visual Fatigue}},
volume = {8},
year = {2010}
}
@article{Robertson2000,
abstract = {The Task Gallery is a window manager that uses interactive 3D graphics to provide direct support for task management and document comparison, lacking from many systems implementing the desktop metaphor. User tasks appear as artwork hung on the walls of a virtual art gallery, with the selected task on a stage. Multiple documents can be selected and displayed side-by-side using 3D space to provide uniform and intuitive scaling. The Task Gallery hosts any Windows application, using a novel redirection mechanism that routes input and output between the 3D environment and unmodified 2D Windows applications. User studies suggest that the Task Gallery helps with task management, is enjoyable to use, and that the 3D metaphor evokes spatial memory and cognition.},
author = {Robertson, George and van Dantzich, Maarten and Robbins, Daniel and Czerwinski, Mary and Hinckley, Ken and Risden, Kirsten and Thiel, David and Gorokhovsky, Vadim},
doi = {10.1145/332040.332482},
file = {:C$\backslash$:/Users/KennyHong/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Robertson et al. - 2000 - The Task Gallery.pdf:pdf},
isbn = {1581132166},
journal = {Proceedings of the SIGCHI conference on Human factors in computing systems  - CHI '00},
keywords = {3d user interfaces,cognition,spatial,spatial memory,window managers},
number = {June},
pages = {494--501},
title = {{The Task Gallery}},
url = {http://portal.acm.org/citation.cfm?doid=332040.332482},
year = {2000}
}

@article{Bower2014,
abstract = {Augmented Reality is poised to profoundly transform Education as we know it. The capacity to overlay rich media onto the real-world for viewing through web-enabled devices such as phones and tablet devices means that information can be made available to students at the exact time and place of need. This has the potential to reduce cognitive overload by providing students with `perfectly situated scaffolding', as well as enable learning in a range of other ways. This paper will review uses of Augmented Reality both in mainstream society and in education, and discuss the pedagogical potentials afforded by the technology. Based on the prevalence of information delivery uses of Augmented Reality in Education, we argue the merit of having students design Augmented Reality experiences in order to develop their higher order thinking capabilities. A case study of `learning by design' using Augmented Reality in high school Visual Art is presented, with samples of student work and their feedback indicating that the approach resulted in high levels of independent thinking, creativity and critical analysis. The paper concludes by establishing a future outlook for Augmented Reality and setting a research agenda going forward.},
author = {Bower, Matt and Howe, Cathie and McCredie, Nerida and Robinson, Austin and Grover, David},
doi = {10.1080/09523987.2014.889400},
file = {:C$\backslash$:/Users/KennyHong/Downloads/Augmented Reality in education cases places and potentials.pdf:pdf},
isbn = {9781479932160},
issn = {14695790},
journal = {Educational Media International},
keywords = {AR,Augmented Reality,design-based learning,higher order thinking,mobile,pedagogy},
number = {1},
pages = {1--15},
publisher = {Routledge},
title = {{Augmented Reality in education - cases, places and potentials}},
url = {http://dx.doi.org/10.1080/09523987.2014.889400},
volume = {51},
year = {2014}
}

@article{Azuma1997,
abstract = {This paper surveys the field of Augmented Reality, in which 3-D virtual objects are integrated into a 3-D real environment in real time. It describes the medical, manufacturing, visualization, path planning, entertainment and military applications that have been explored. This paper describes the characteristics of Augmented Reality systems, including a detailed discussion of the tradeoffs between optical and video blending approaches. Registration and sensing errors are two of the biggest problems in building effective Augmented Reality systems, so this paper summarizes current efforts to overcome these problems. Future directions and areas requiring further research are discussed. This survey provides a starting point for anyone interested in researching or using Augmented Reality.},
author = {Azuma, Ronald},
doi = {10.1561/1100000049},
file = {:C$\backslash$:/Users/KennyHong/Downloads/Augmented Reality presence.pdf:pdf},
isbn = {1551-3955},
issn = {1551-3955},
number = {August},
pages = {355--385},
pmid = {9708264137},
title = {{A Survey of Augmented Reality}},
volume = {4},
year = {1997}
}

@article{Boulanger2004,
abstract = {Augmented Reality (AR) is a departure from standard virtual reality in a sense that it allows users to see computer generated virtual objects superimposed over the real world through the use of see-through head-mounted display. Users of such system can interact in the real/virtual world using additional information, such as 3D virtual models and instructions on how to perform these tasks in the form of video clips, annotations, speech instructions, and images. In this paper, we describe a prototype of a collaborative industrial Tele-training system. The distributed aspect of this system will enable users on remote sites to collaborate on training tasks by sharing the view of the local user equipped with a wearable computer. The users can interactively manipulate virtual objects that substitute real objects allowing the trainee to try out and discuss the various tasks that needs to be performed. Experimental results are presented.},
author = {Boulanger, Pierre},
doi = {10.1109/CCCRV.2004.1301462},
file = {:C$\backslash$:/Users/KennyHong/Downloads/C-2004-CRV-Tele.pdf:pdf},
isbn = {0769521274},
journal = {Proceedings - 1st Canadian Conference on Computer and Robot Vision},
pages = {320--328},
title = {{Application of augmented reality to industrial Tele-training}},
year = {2004}
}
@article{Zhong2003,
author = {Zhong, Xiaowei and Liu, Peiran and Georganas, Nicolas D},
doi = {10.1524/itit.45.1.7.19032},
file = {:C$\backslash$:/Users/KennyHong/Downloads/10.1.1.73.784.pdf:pdf},
issn = {2196-7032},
keywords = {augmented reality,computer supported collaborative work,industrial training,wearable computing},
pages = {7--19},
title = {{Designing a Vision-based Collaborative Augmented Reality Application for Industrial Training}},
volume = {45},
year = {2003}
}
@article{Grubert2017,
abstract = {Augmented Reality is a technique that enables users to interact with their physical environment through the overlay of digital information. While being researched for decades, more recently, Augmented Reality moved out of the research labs and into the field. While most of the applications are used sporadically and for one particular task only, current and future scenarios will provide a continuous and multi-purpose user experience. Therefore, in this paper, we present the concept of Pervasive Augmented Reality, aiming to provide such an experience by sensing the user's current context and adapting the AR system based on the changing requirements and constraints. We present a taxonomy for Pervasive Augmented Reality and context-aware Augmented Reality, which classifies context sources and context targets relevant for implementing such a context-aware, continuous Augmented Reality experience. We further summarize existing approaches that contribute towards Pervasive Augmented Reality. Based our taxonomy and survey, we identify challenges for future research directions in Pervasive Augmented Reality.},
author = {Grubert, Jens and Langlotz, Tobias and Zollmann, Stefanie and Regenbrecht, Holger},
doi = {10.1109/TVCG.2016.2543720},
file = {:C$\backslash$:/Users/KennyHong/Downloads/GrubertIEEETVCG2016.pdf:pdf},
isbn = {1077-2626},
issn = {10772626},
journal = {IEEE Transactions on Visualization and Computer Graphics},
keywords = {Augmented reality,adaptivity,context,context-awareness,mixed reality,pervasive augmented reality,survey,taxonomy},
number = {6},
pages = {1706--1724},
pmid = {27008668},
title = {{Towards pervasive augmented reality: Context-awareness in augmented reality}},
volume = {23},
year = {2017}
}
@article{Billinghurst2017,
abstract = {Navigation has been a popular area of research in both academia and industry. Combined with maps, and different localization technologies, navigation systems have become robust and more usable. By combining navigation with augmented reality, it can be improved further to become realistic and user friendly. This paper surveys existing researches carried out in this area, describes existing techniques for building augmented reality navigation systems, and the problems faced.},
archivePrefix = {arXiv},
arxivId = {1708.05006},
author = {Billinghurst, Mark and Clark, Adrian and Lee, Gun},
doi = {10.1561/1100000049},
eprint = {1708.05006},
file = {:C$\backslash$:/Users/KennyHong/Downloads/9781601989215-summary.pdf:pdf},
isbn = {1551-3955},
issn = {1551-3955},
pmid = {9708264137},
title = {{A Survey of Augmented Reality}},
url = {http://arxiv.org/abs/1708.05006},
year = {2017}
}
@article{vanKrevelen2010,
abstract = {We are on the verge of ubiquitously adopting Augmented Reality (AR) technologies to enhance our perception and help us see, hear, and feel our environments in new and enriched ways. AR will support us in fields such as education, maintenance, design and reconnaissance, to name but a few. This paper describes the field of AR, including a brief definition and development history, the enabling technologies and their characteristics. It surveys the state of the art by reviewing some recent applications of AR technology as well as some known limitations regarding human factors in the use of AR systems that developers will need to overcome.},
author = {van Krevelen, D.W.F. and Poelman, R.},
doi = {10.1155/2011/721827},
file = {:C$\backslash$:/Users/KennyHong/Downloads/ijvr-2010.pdf:pdf},
issn = {10255834},
journal = {The International Journal of Virtual Reality},
number = {2},
pages = {1--20},
title = {{A Survey of Augmented Reality Technologies, Applications and Limitations}},
url = {http://kjcomps.6te.net/upload/paper1 .pdf},
volume = {9},
year = {2010}
}

@misc{Hololens,
       title = "Microsoft Hololens",
       author = "Microsoft",
       howpublished = "\url{https://www.microsoft.com/en-ca/hololens}",
       year = "2018"
    }